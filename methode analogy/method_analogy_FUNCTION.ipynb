{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_etape_analogy(model, a, b): \n",
    "#il faut normaliser les vecteurs du modèle\n",
    "    model.unit_normalize_all()\n",
    "\n",
    "#on trouve les vecteurs associés aux mots \n",
    "    vect_a = model.get_vector('a')\n",
    "    vect_b = model.get_vector('b')\n",
    "    diff_visée = (vect_a - vect_b)/np.linalg.norm(vect_a - vect_b)\n",
    "#me donne une ligne et 24065 colonnes\n",
    "#chaque colonne correspond à la cos_sim entre un mot et le vect diff she-he\n",
    "\n",
    "    mat_1 = linear_kernel((diff_visée).reshape(1,-1), X) \n",
    "    nb_words = len(model.index_to_key)\n",
    "    \n",
    "#matrice donne les similarités cos entre le vecteur diff et tous les autres vecteurs\n",
    "    sim_mat = np.zeros((nb_words,nb_words))\n",
    "    xmat_1 = np.array(mat_1[0,:])\n",
    "    sim_mat = np.tile(xmat_1[np.newaxis,:], (nb_words,1))-np.tile(xmat_1[:,np.newaxis], (1,nb_words))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouver_analogy(model, sim_mat, n):\n",
    "# Supposons que sim_mat soit votre matrice de similarité et model votre array de vecteurs\n",
    "    best_coefs = -np.ones(n)\n",
    "    indices_best = [0] * n\n",
    "    k = 10*n\n",
    "    while np.min(best_coefs) == -1: \n",
    "# Utilisez argpartition pour obtenir les indices triés des 1000 plus grands coefficients de toute la matrice\n",
    "        sorted_indices = np.argpartition(-sim_mat, 10**k, axis=None)[:10**k]\n",
    "\n",
    "# Utilisez unravel_index pour obtenir les indices dans la matrice d'origine\n",
    "        indices_in_sim_mat = np.unravel_index(sorted_indices, sim_mat.shape)\n",
    "\n",
    "# Parcourez les indices et mettez à jour les listes best_coefs et indices_best\n",
    "        for i, j in zip(*indices_in_sim_mat):\n",
    "            if sim_mat[i, j] > np.min(best_coefs):\n",
    "                if np.linalg.norm(model[i] - model[j]) < 1:\n",
    "                    index = np.argmin(best_coefs)\n",
    "                best_coefs[index] = sim_mat[i, j]\n",
    "                indices_best[index] = (i, j)\n",
    "        k += 1 \n",
    "    return indices_best, best_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reveal_analogy(model, indices_best, best_coefs):\n",
    "    for i,j in indices_best :\n",
    "        analog_she = model.index_to_key[i]\n",
    "        analog_he = model.index_to_key[j]\n",
    "    return (analog_she, analog_he)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
