{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7664012908935547),\n",
       " ('boy', 0.6824871301651001),\n",
       " ('teenager', 0.6586930155754089),\n",
       " ('teenage_girl', 0.6147903203964233),\n",
       " ('girl', 0.5921714305877686),\n",
       " ('suspected_purse_snatcher', 0.571636438369751),\n",
       " ('robber', 0.5585119128227234),\n",
       " ('Robbery_suspect', 0.5584409832954407),\n",
       " ('teen_ager', 0.5549196600914001),\n",
       " ('men', 0.5489763021469116)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.sort_by_descending_frequency()\n",
    "first_model.unit_normalize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifier_chaine(chaine) :\n",
    "    if chaine.islower() and chaine.isalpha() and len(chaine)<20 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['in', 'for', 'that', 'is', 'on', 'with', 'said', 'was', 'the', 'at'], 24065)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sorted = first_model.index_to_key[:50000]\n",
    "words_sorted = [word for word in words_sorted if verifier_chaine(word)]\n",
    "words_sorted[:10], len(words_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = first_model.vector_size\n",
    "model = models.keyedvectors.KeyedVectors(vector_size, count=0)\n",
    "for word in words_sorted :\n",
    "    model[word] = first_model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7664012908935547),\n",
       " ('boy', 0.6824870109558105),\n",
       " ('teenager', 0.6586930155754089),\n",
       " ('girl', 0.5921714305877686),\n",
       " ('robber', 0.5585119128227234),\n",
       " ('men', 0.5489763021469116),\n",
       " ('guy', 0.5420035719871521),\n",
       " ('person', 0.5342026352882385),\n",
       " ('gentleman', 0.5337990522384644),\n",
       " ('motorcyclist', 0.5336882472038269)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rappels de concepts statistiques** : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. La p-valeur \n",
    "\n",
    "La p-valeur, ou valeur de probabilité, est un concept important en statistique qui est utilisé pour évaluer la validité d'une hypothèse nulle dans le cadre d'un test statistique. Elle est souvent associée aux tests d'hypothèses et joue un rôle crucial dans la prise de décisions statistiques.\n",
    "\n",
    "Voici comment la p-valeur fonctionne :\n",
    "\n",
    "1. **Formulation des hypothèses :** Lorsqu'on effectue un test statistique, on formule généralement deux hypothèses. L'hypothèse nulle (H0) stipule qu'il n'y a pas d'effet ou de différence, tandis que l'hypothèse alternative (H1) suggère qu'il y a un effet ou une différence.\n",
    "\n",
    "2. **Collecte des données et calcul de la statistique de test :** On collecte des données et on calcule une statistique de test à partir de ces données. Cette statistique de test dépend du type de test statistique que l'on utilise (par exemple, le test t, le test de chi-carré, le test F, etc.).\n",
    "\n",
    "3. **Calcul de la p-valeur :** La p-valeur est la probabilité d'observer une statistique de test aussi extrême, ou plus extrême, que celle obtenue, sous l'hypothèse nulle. En d'autres termes, c'est la probabilité que les résultats observés soient dus au hasard, sachant que l'hypothèse nulle est vraie.\n",
    "\n",
    "4. **Comparaison avec le seuil de signification :** On compare ensuite la p-valeur à un seuil de signification prédéfini, généralement noté alpha (α). Si la p-valeur est inférieure à alpha, on rejette l'hypothèse nulle au profit de l'hypothèse alternative. Si la p-valeur est supérieure à alpha, on ne rejette pas l'hypothèse nulle.\n",
    "\n",
    "En résumé, une petite p-valeur suggère que les résultats observés sont peu probables sous l'hypothèse nulle, ce qui conduit à la remise en question de cette hypothèse. En revanche, une grande p-valeur indique que les résultats sont compatibles avec l'hypothèse nulle, et il n'y a pas suffisamment de preuves pour la rejeter.\n",
    "\n",
    "Il est essentiel de noter que la p-valeur ne fournit pas la probabilité que l'hypothèse nulle soit vraie ou fausse, mais plutôt la probabilité d'observer les données actuelles ou quelque chose de plus extrême si l'hypothèse nulle est vraie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Taille d'effet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vidéo sur la cohen's d method : https://www.youtube.com/watch?v=IetVSlrndpI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 1** : coder le test de WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vector(list_word, model) :\n",
    "    #list_word doit être une liste de string\n",
    "    arr_vector = np.zeros((len(list_word), model.vector_size))\n",
    "    for i, word in enumerate(list_word) :\n",
    "        arr_vector[i] = model[word]\n",
    "    return arr_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contrairement à l'article, j'ai pas equationS dans mon vocabulaire\n",
    "X1 = ['math', 'algebra', 'geometry', 'calculus', 'equation', 'computation', 'numbers', 'addition']\n",
    "X1_vec = word_to_vector(X1, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "B1 = ['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter']\n",
    "B1_vec = word_to_vector(B1, model)\n",
    "for i in range(np.shape(X1_vec)[0]) :\n",
    "    sim_x_B1 = model.cosine_similarities(X1_vec[i], B1_vec)\n",
    "print(sim_x_B1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.013237026812653103\n"
     ]
    }
   ],
   "source": [
    "moyenne = np.mean(sim_x_B1)\n",
    "print(moyenne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_w_A_B(w, A, B, model) :\n",
    "    #w est déjà un vecteur de mot\n",
    "    sim_w_A = model.cosine_similarities(w, A)\n",
    "    mean_w_A = np.mean(sim_w_A)\n",
    "    sim_w_B = model.cosine_similarities(w, B)\n",
    "    mean_w_B = np.mean(sim_w_B)\n",
    "    return mean_w_A - mean_w_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0432115584222808"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1 = ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']\n",
    "A1_vec = word_to_vector(A1, model)\n",
    "s_w_A_B(X1_vec[0], B1_vec, A1_vec, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weat(X,Y,A,B, model): #v2 permet de déjà débuter le calcul de l'effectsize qui devient très redondant sinon\n",
    "    # X,Y sont des listes de mots_test de même taille\n",
    "    #ex : X = math words(calculus, equations, etc.) et Y = arts words (poetry, art, etc.)\n",
    "    # A,B are lists of attribute words\n",
    "    #ex : A = female attributes (women, sister, girl, etc.) et B = male attributes (man, boy, etc.)\n",
    "    X = word_to_vector(X, model)\n",
    "    Y = word_to_vector(Y, model)\n",
    "    A = word_to_vector(A, model)\n",
    "    B = word_to_vector(B, model)\n",
    "    #j'utilise la cosinus_similarité, donc les vecteurs n'ont pas besoin d'être normalisés\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    mean_x = 0 #les calculs de moyenne servent par la suite pour le calcul de l'effectsize\n",
    "    mean_y = 0\n",
    "    mean_glob = 0 \n",
    "    for i in range(np.shape(X)[0]) :\n",
    "        xi_AB = s_w_A_B(X[i], A, B, model)\n",
    "        sum_x += xi_AB\n",
    "        mean_x += xi_AB\n",
    "        mean_glob += xi_AB\n",
    "    for i in range(np.shape(Y)[0]) :    \n",
    "        yi_AB = s_w_A_B(Y[i], A, B, model)\n",
    "        sum_y += yi_AB\n",
    "        mean_y += yi_AB\n",
    "        mean_glob += yi_AB\n",
    "    mean_x = mean_x/np.shape(X)[0]\n",
    "    mean_y = mean_y/np.shape(Y)[0]\n",
    "    mean_glob = mean_glob/(np.shape(X)[0] + np.shape(Y)[0])\n",
    "    return [sum_x - sum_y, mean_x, mean_y, mean_glob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2569912484834471\n"
     ]
    }
   ],
   "source": [
    "X1 = ['math', 'algebra', 'geometry', 'calculus', 'equation', 'computation', 'numbers', 'addition']\n",
    "Y1 = ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture']\n",
    "Y1_vec = word_to_vector(Y1, model)\n",
    "result1 = test_weat(X1, Y1, A1, B1, model)[0]\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 2** : vérifier ses caractéristiques statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord, on implémente le calcul de la taille d'effet (effect size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_size(X,Y,A,B,model):\n",
    "    result, mean_x, mean_y, mean_glob = test_weat(X,Y,A,B,model)\n",
    "    ecart_type = 0\n",
    "    X = word_to_vector(X, model)\n",
    "    Y = word_to_vector(Y, model)\n",
    "    A = word_to_vector(A, model)\n",
    "    B = word_to_vector(B, model)\n",
    "    for i in range(np.shape(X)[0]) :\n",
    "        xi_AB = s_w_A_B(X[i], A, B, model)\n",
    "        ecart_type += (xi_AB - mean_glob)**2\n",
    "    for i in range(np.shape(Y)[0]) :\n",
    "        yi_AB = s_w_A_B(Y[i], A, B, model)\n",
    "        ecart_type += (yi_AB - mean_glob)**2\n",
    "    ecart_type = ecart_type/(np.shape(X)[0] + np.shape(Y)[0]-1)\n",
    "    ecart_type = np.sqrt(ecart_type)\n",
    "    effect_size = (mean_x - mean_y)/ecart_type\n",
    "    return effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988407824670586"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect_size(X1, Y1, A1, B1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'article, ils obtiennent un effect_size de 1,06 sur le word embedding GloVe. Les ordres de grandeur semblent cohérents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, il faut implémenter le calcul de la p-valeur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui est décrit dans l'article : Let $ \\{(X_i, Y_i)\\}_i $ denote all the partitions of $ X \\cup Y $ into two sets of equal size. The one-sided p-value of the permutation test is:\n",
    "\n",
    "$ P_r \\left[ s(X_i, Y_i, A, B) > s(X, Y, A, B) \\right] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La procédure décrite dans l'article indique qu'une permutation test doit être utilisée pour évaluer la p-valeur. Un test de permutation implique de réarranger aléatoirement les éléments entre les groupes (ici, X et Y) et de recalculer la statistique de test pour chaque arrangement. Cela permet de construire une distribution nulle de la statistique de test sous l'hypothèse nulle (pas d'association entre les groupes).\n",
    "\n",
    "La p-valeur est ensuite calculée comme la proportion des arrangements aléatoires qui génèrent une statistique de test aussi extrême ou plus extrême que la statistique observée dans les données réelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine les ensembles X et Y\n",
    "ensemble_combine = X1 + Y1\n",
    "len(ensemble_combine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "8\n"
     ]
    }
   ],
   "source": [
    " # Calcule la taille d'un seul ensemble après permutation\n",
    "taille_ensemble = len(ensemble_combine) // 2\n",
    "\n",
    "# Génère toutes les partitions possibles de X U Y en deux ensembles de taille égale\n",
    "partitions = list(itertools.combinations(ensemble_combine, taille_ensemble))\n",
    "\n",
    "print(type(partitions[0][0]))\n",
    "print(len(partitions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_valeur(X,Y,A,B,model, stat_obs):\n",
    "    # Combine les ensembles X et Y qui sont des listes de string\n",
    "    ensemble_combine = X + Y\n",
    "    # Calcule la taille d'un seul ensemble après permutation\n",
    "    taille_ensemble = len(ensemble_combine) // 2\n",
    "    # Génère toutes les partitions possibles de X U Y en deux ensembles de taille égale \n",
    "    #--> liste de tuples, chaque tuple contient 8 strings\n",
    "    partitions = list(itertools.combinations(ensemble_combine, taille_ensemble))\n",
    "    # Pour chaque partition, calcule la statistique de test et compte les arrangements extrêmes\n",
    "    count = 0\n",
    "    for partition in partitions:\n",
    "        X_perm = list(partition)\n",
    "        Y_perm = list(set(ensemble_combine) - set(X_perm))\n",
    "        stat = test_weat(X_perm,Y_perm,A,B,model)[0]  #Calcule la statistique de test pour cette permutation\n",
    "        if stat >= stat_obs:  # Compare la statistique de test de la permutation à la statistique observée\n",
    "            count += 1\n",
    "    # Calcule la p-valeur en divisant le nombre d'arrangements extrêmes par le nombre total de permutations\n",
    "    p_valeur = count/ len(partitions)\n",
    "    return p_valeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019502719502719503"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_valeur(X1, Y1, A1, B1, model, result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'article obtient une p-valeur de $10^-2$ sur le word embedding GloVe. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
